

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>dabl.search.RandomSuccessiveHalving &mdash; dabl  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/js/copybutton.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/project-template.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-dataframe.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="dabl.plot.class_hists" href="dabl.plot.class_hists.html" />
    <link rel="prev" title="dabl.search.GridSuccessiveHalving" href="dabl.search.GridSuccessiveHalving.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> dabl
          

          
          </a>

          
            
            
              <div class="version">
                0.1.9-dev
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick_start.html">Quickstart to ML with dabl</a></li>
</ul>
<p class="caption"><span class="caption-text">Documentation</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../user_guide.html">Machine Learning with dabl</a></li>
<li class="toctree-l1"><a class="reference internal" href="../concepts_term.html">Concepts and terminology</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../api.html">dabl API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../api.html#high-level-api">High-level API</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../api.html#full-api">Full API</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../api.html#datasets">Datasets</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../api.html#model-search">Model Search</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="dabl.search.GridSuccessiveHalving.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dabl.search</span></code>.GridSuccessiveHalving</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dabl.search</span></code>.RandomSuccessiveHalving</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#plotting">Plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#portfolios">Portfolios</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">General examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html#plotting-examples">Plotting examples</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">dabl</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../api.html">dabl API</a> &raquo;</li>
        
      <li><code class="xref py py-mod docutils literal notranslate"><span class="pre">dabl.search</span></code>.RandomSuccessiveHalving</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/generated/dabl.search.RandomSuccessiveHalving.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="dabl-search-randomsuccessivehalving">
<h1><code class="xref py py-mod docutils literal notranslate"><span class="pre">dabl.search</span></code>.RandomSuccessiveHalving<a class="headerlink" href="#dabl-search-randomsuccessivehalving" title="Permalink to this headline">¶</a></h1>
<dl class="function">
<dt id="dabl.search.RandomSuccessiveHalving">
<code class="sig-prename descclassname">dabl.search.</code><code class="sig-name descname">RandomSuccessiveHalving</code><span class="sig-paren">(</span><em class="sig-param">estimator</em>, <em class="sig-param">param_distributions</em>, <em class="sig-param">n_candidates='auto'</em>, <em class="sig-param">scoring=None</em>, <em class="sig-param">n_jobs=None</em>, <em class="sig-param">refit=True</em>, <em class="sig-param">verbose=0</em>, <em class="sig-param">cv=5</em>, <em class="sig-param">pre_dispatch='2*n_jobs'</em>, <em class="sig-param">random_state=None</em>, <em class="sig-param">error_score=nan</em>, <em class="sig-param">return_train_score=True</em>, <em class="sig-param">max_budget='auto'</em>, <em class="sig-param">budget_on='n_samples'</em>, <em class="sig-param">ratio=3</em>, <em class="sig-param">r_min='auto'</em>, <em class="sig-param">aggressive_elimination=False</em>, <em class="sig-param">force_exhaust_budget=False</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/dabl/dabl/blob/a5cd0e9/dabl/search.py#L558"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dabl.search.RandomSuccessiveHalving" title="Permalink to this definition">¶</a></dt>
<dd><p>Randomized search with successive halving.</p>
<p>The search strategy for hyper-parameter optimization starts evaluating all
the candidates with a small amount a resource and iteratively selects the
best candidates, using more and more resources.</p>
<p>Read more in the <a class="reference internal" href="../user_guide.html#successive-halving-user-guide"><span class="std std-ref">User guide</span></a>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>estimator</strong><span class="classifier">estimator object.</span></dt><dd><p>This is assumed to implement the scikit-learn estimator interface.
Either estimator needs to provide a <code class="docutils literal notranslate"><span class="pre">score</span></code> function,
or <code class="docutils literal notranslate"><span class="pre">scoring</span></code> must be passed.</p>
</dd>
<dt><strong>param_distributions</strong><span class="classifier">dict</span></dt><dd><p>Dictionary with parameters names (string) as keys and distributions
or lists of parameters to try. Distributions must provide a <code class="docutils literal notranslate"><span class="pre">rvs</span></code>
method for sampling (such as those from scipy.stats.distributions).
If a list is given, it is sampled uniformly.</p>
</dd>
<dt><strong>n_candidates: int, optional(default=’auto’)</strong></dt><dd><p>The number of candidate parameters to sample. By default this will
sample enough candidates so that the last iteration uses as many
resources as possible. Note that <code class="docutils literal notranslate"><span class="pre">force_exhaust_budget</span></code> has no
effect in this case.</p>
</dd>
<dt><strong>scoring</strong><span class="classifier">string, callable, or None, default: None</span></dt><dd><p>A single string (see <a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter" title="(in scikit-learn v0.23)"><span>The scoring parameter: defining model evaluation rules</span></a>) or a callable
(see <a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html#scoring" title="(in scikit-learn v0.23)"><span>Defining your scoring strategy from metric functions</span></a>) to evaluate the predictions on the test set.
If None, the estimator’s score method is used.</p>
</dd>
<dt><strong>n_jobs</strong><span class="classifier">int or None, optional (default=None)</span></dt><dd><p>Number of jobs to run in parallel.
<code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code> context.
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <a class="reference external" href="https://scikit-learn.org/stable/glossary.html#term-n-jobs" title="(in scikit-learn v0.23)"><span class="xref std std-term">Glossary</span></a>
for more details.</p>
</dd>
<dt><strong>pre_dispatch</strong><span class="classifier">int, or string, optional</span></dt><dd><p>Controls the number of jobs that get dispatched during parallel
execution. Reducing this number can be useful to avoid an
explosion of memory consumption when more jobs get dispatched
than CPUs can process. This parameter can be:</p>
<blockquote>
<div><ul class="simple">
<li><p>None, in which case all the jobs are immediately
created and spawned. Use this for lightweight and
fast-running jobs, to avoid delays due to on-demand
spawning of the jobs</p></li>
<li><p>An int, giving the exact number of total jobs that are
spawned</p></li>
<li><p>A string, giving an expression as a function of n_jobs,
as in ‘2*n_jobs’</p></li>
</ul>
</div></blockquote>
</dd>
<dt><strong>cv</strong><span class="classifier">int, cross-validation generator or an iterable, optional (default=5)</span></dt><dd><p>Determines the cross-validation splitting strategy.
Possible inputs for cv are:</p>
<ul class="simple">
<li><p>integer, to specify the number of folds in a <cite>(Stratified)KFold</cite>,</p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/glossary.html#term-cv-splitter" title="(in scikit-learn v0.23)"><span class="xref std std-term">CV splitter</span></a>,</p></li>
<li><p>An iterable yielding (train, test) splits as arrays of indices.</p></li>
</ul>
<p>For integer/None inputs, if the estimator is a classifier and <code class="docutils literal notranslate"><span class="pre">y</span></code> is
either binary or multiclass, <code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code> is used. In all
other cases, <code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code> is used.</p>
<p>Refer to <a class="reference external" href="https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation" title="(in scikit-learn v0.23)"><span class="xref std std-ref">User Guide</span></a> for the various
cross-validation strategies that can be used here.</p>
</dd>
<dt><strong>refit</strong><span class="classifier">boolean, default=True</span></dt><dd><p>If True, refit an estimator using the best found parameters on the
whole dataset.</p>
<p>The refitted estimator is made available at the <code class="docutils literal notranslate"><span class="pre">best_estimator_</span></code>
attribute and permits using <code class="docutils literal notranslate"><span class="pre">predict</span></code> directly on this
<code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> instance.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">integer</span></dt><dd><p>Controls the verbosity: the higher, the more messages.</p>
</dd>
<dt><strong>error_score</strong><span class="classifier">‘raise’ or numeric</span></dt><dd><p>Value to assign to the score if an error occurs in estimator fitting.
If set to ‘raise’, the error is raised. If a numeric value is given,
FitFailedWarning is raised. This parameter does not affect the refit
step, which will always raise the error. Default is <code class="docutils literal notranslate"><span class="pre">np.nan</span></code></p>
</dd>
<dt><strong>return_train_score</strong><span class="classifier">boolean, default=False</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">False</span></code>, the <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> attribute will not include training
scores.
Computing training scores is used to get insights on how different
parameter settings impact the overfitting/underfitting trade-off.
However computing the scores on the training set can be computationally
expensive and is not strictly required to select the parameters that
yield the best generalization performance.</p>
</dd>
<dt><strong>max_budget</strong><span class="classifier">int, optional(default=’auto’)</span></dt><dd><p>The maximum number of resources that any candidate is allowed to use
for a given iteration. By default, this is set <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> when
<code class="docutils literal notranslate"><span class="pre">budget_on='n_samples'</span></code> (default), else an error is raised.</p>
</dd>
<dt><strong>budget_on</strong><span class="classifier"><cite>n_samples</cite> or str, optional(default=’n_samples’)</span></dt><dd><p>Defines the nature of the budget. By default, the budget is the number
of samples. It can also be set to any parameter of the base estimator
that accepts positive integer values, e.g. ‘n_iterations’ or
‘n_estimators’ for a gradient boosting estimator. In this case
<code class="docutils literal notranslate"><span class="pre">max_budget</span></code> cannot be ‘auto’.</p>
</dd>
<dt><strong>ratio</strong><span class="classifier">int or float, optional(default=3)</span></dt><dd><p>The ‘halving’ parameter, which determines the proportion of candidates
that are selected for the next iteration. For example, <code class="docutils literal notranslate"><span class="pre">ratio=3</span></code>
means that only one third of the candidates are selected.</p>
</dd>
<dt><strong>r_min</strong><span class="classifier">int, optional(default=’auto’)</span></dt><dd><p>The minimum amount of resource that any candidate is allowed to use for
a given iteration. Equivalently, this defines the amount of resources
that are allocated for each candidate at the first iteration. By
default, this is set to:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_splits</span> <span class="pre">*</span> <span class="pre">2</span></code> when <code class="docutils literal notranslate"><span class="pre">budget_on='n_samples'</span></code> for a regression
problem</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_classes</span> <span class="pre">*</span> <span class="pre">n_splits</span> <span class="pre">*</span> <span class="pre">2</span></code> when <code class="docutils literal notranslate"><span class="pre">budget_on='n_samples'</span></code> for a
regression problem</p></li>
<li><p>The highest possible value satisfying the constraint
<code class="docutils literal notranslate"><span class="pre">force_exhaust_budget=True</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">1</span></code> when <code class="docutils literal notranslate"><span class="pre">budget_on!='n_samples'</span></code></p></li>
</ul>
<p>Note that the amount of resources used at each iteration is always a
multiple of <code class="docutils literal notranslate"><span class="pre">r_min</span></code>.</p>
</dd>
<dt><strong>aggressive_elimination</strong><span class="classifier">bool, optional(default=False)</span></dt><dd><p>This is only relevant in cases where there isn’t enough budget to
eliminate enough candidates at the last iteration. If <code class="docutils literal notranslate"><span class="pre">True</span></code>, then
the search process will ‘replay’ the first iteration for as long as
needed until the number of candidates is small enough. This is
<code class="docutils literal notranslate"><span class="pre">False</span></code> by default, which means that the last iteration may evaluate
more than <code class="docutils literal notranslate"><span class="pre">ratio</span></code> candidates.</p>
</dd>
<dt><strong>force_exhaust_budget</strong><span class="classifier">bool, optional(default=False)</span></dt><dd><p>If True, then <code class="docutils literal notranslate"><span class="pre">r_min</span></code> is set to a specific value such that the
last iteration uses as much budget as possible. Namely, the last
iteration uses the highest value smaller than <code class="docutils literal notranslate"><span class="pre">max_budget</span></code> that is a
multiple of both <code class="docutils literal notranslate"><span class="pre">r_min</span></code> and <code class="docutils literal notranslate"><span class="pre">ratio</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="dabl.search.GridSuccessiveHalving.html#dabl.search.GridSuccessiveHalving" title="dabl.search.GridSuccessiveHalving"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSuccessiveHalving</span></code></a></dt><dd><p>Search over a grid of parameters using successive halving.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The parameters selected are those that maximize the score of the held-out
data, according to the scoring parameter.</p>
<p>If <cite>n_jobs</cite> was set to a value higher than one, the data is copied for each
parameter setting(and not <cite>n_jobs</cite> times). This is done for efficiency
reasons if individual jobs take very little time, but may raise errors if
the dataset is large and not enough memory is available.  A workaround in
this case is to set <cite>pre_dispatch</cite>. Then, the memory is copied only
<cite>pre_dispatch</cite> many times. A reasonable value for <cite>pre_dispatch</cite> is <cite>2 *
n_jobs</cite>.</p>
<dl class="field-list">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl>
<dt><strong>n_candidates_</strong><span class="classifier">int</span></dt><dd><p>The number of candidate parameters that were evaluated at the first
iteration.</p>
</dd>
<dt><strong>n_remaining_candidates_</strong><span class="classifier">int</span></dt><dd><p>The number of candidate parameters that are left after the last
iteration.</p>
</dd>
<dt><strong>max_budget_</strong><span class="classifier">int</span></dt><dd><p>The maximum number of resources that any candidate is allowed to use
for a given iteration. Note that since the number of resources used at
each iteration must be a multiple of <code class="docutils literal notranslate"><span class="pre">r_min_</span></code>, the actual number of
resources used at the last iteration may be smaller than
<code class="docutils literal notranslate"><span class="pre">max_budget_</span></code>.</p>
</dd>
<dt><strong>r_min_</strong><span class="classifier">int</span></dt><dd><p>The amount of resources that are allocated for each candidate at the
first iteration.</p>
</dd>
<dt><strong>n_iterations_</strong><span class="classifier">int</span></dt><dd><p>The actual number of iterations that were run. This is equal to
<code class="docutils literal notranslate"><span class="pre">n_required_iterations_</span></code> if <code class="docutils literal notranslate"><span class="pre">aggressive_elimination</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.
Else, this is equal to <code class="docutils literal notranslate"><span class="pre">min(n_possible_iterations_,</span>
<span class="pre">n_required_iterations_)</span></code>.</p>
</dd>
<dt><strong>n_possible_iterations_</strong><span class="classifier">int</span></dt><dd><p>The number of iterations that are possible starting with <code class="docutils literal notranslate"><span class="pre">r_min_</span></code>
resources and without exceeding <code class="docutils literal notranslate"><span class="pre">max_budget_</span></code>.</p>
</dd>
<dt><strong>n_required_iterations_</strong><span class="classifier">int</span></dt><dd><p>The number of iterations that are required to end up with less than
<code class="docutils literal notranslate"><span class="pre">ratio</span></code> candidates at the last iteration, starting with <code class="docutils literal notranslate"><span class="pre">r_min_</span></code>
resources. This will be smaller than <code class="docutils literal notranslate"><span class="pre">n_possible_iterations_</span></code> when
there isn’t enough budget.</p>
</dd>
<dt><strong>cv_results_</strong><span class="classifier">dict of numpy (masked) ndarrays</span></dt><dd><p>A dict with keys as column headers and values as columns, that can be
imported into a pandas <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>.</p>
<p>For instance the below given table</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 22%" />
<col style="width: 20%" />
<col style="width: 30%" />
<col style="width: 5%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>param_kernel</p></th>
<th class="head"><p>param_gamma</p></th>
<th class="head"><p>split0_test_score</p></th>
<th class="head"><p>…</p></th>
<th class="head"><p>rank_test_score</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>‘rbf’</p></td>
<td><p>0.1</p></td>
<td><p>0.80</p></td>
<td><p>…</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd"><td><p>‘rbf’</p></td>
<td><p>0.2</p></td>
<td><p>0.90</p></td>
<td><p>…</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p>‘rbf’</p></td>
<td><p>0.3</p></td>
<td><p>0.70</p></td>
<td><p>…</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
<p>will be represented by a <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> dict of:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="s1">&#39;param_kernel&#39;</span> <span class="p">:</span> <span class="n">masked_array</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">],</span>
                              <span class="n">mask</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span>
<span class="s1">&#39;param_gamma&#39;</span>  <span class="p">:</span> <span class="n">masked_array</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span> <span class="mf">0.2</span> <span class="mf">0.3</span><span class="p">],</span> <span class="n">mask</span> <span class="o">=</span> <span class="kc">False</span><span class="p">),</span>
<span class="s1">&#39;split0_test_score&#39;</span>  <span class="p">:</span> <span class="p">[</span><span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.90</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">],</span>
<span class="s1">&#39;split1_test_score&#39;</span>  <span class="p">:</span> <span class="p">[</span><span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">],</span>
<span class="s1">&#39;mean_test_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.81</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">],</span>
<span class="s1">&#39;std_test_score&#39;</span>     <span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.20</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
<span class="s1">&#39;rank_test_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="s1">&#39;split0_train_score&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.92</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">],</span>
<span class="s1">&#39;split1_train_score&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">],</span>
<span class="s1">&#39;mean_train_score&#39;</span>   <span class="p">:</span> <span class="p">[</span><span class="mf">0.81</span><span class="p">,</span> <span class="mf">0.74</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">],</span>
<span class="s1">&#39;std_train_score&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.19</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
<span class="s1">&#39;mean_fit_time&#39;</span>      <span class="p">:</span> <span class="p">[</span><span class="mf">0.73</span><span class="p">,</span> <span class="mf">0.63</span><span class="p">,</span> <span class="mf">0.43</span><span class="p">],</span>
<span class="s1">&#39;std_fit_time&#39;</span>       <span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
<span class="s1">&#39;mean_score_time&#39;</span>    <span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.06</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">],</span>
<span class="s1">&#39;std_score_time&#39;</span>     <span class="p">:</span> <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">],</span>
<span class="s1">&#39;params&#39;</span>             <span class="p">:</span> <span class="p">[{</span><span class="s1">&#39;kernel&#39;</span> <span class="p">:</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span> <span class="p">:</span> <span class="mf">0.1</span><span class="p">},</span> <span class="o">...</span><span class="p">],</span>
<span class="p">}</span>
</pre></div>
</div>
<p>NOTE</p>
<p>The key <code class="docutils literal notranslate"><span class="pre">'params'</span></code> is used to store a list of parameter
settings dicts for all the parameter candidates.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">mean_fit_time</span></code>, <code class="docutils literal notranslate"><span class="pre">std_fit_time</span></code>, <code class="docutils literal notranslate"><span class="pre">mean_score_time</span></code> and
<code class="docutils literal notranslate"><span class="pre">std_score_time</span></code> are all in seconds.</p>
</dd>
<dt><strong>best_estimator_</strong><span class="classifier">estimator or dict</span></dt><dd><p>Estimator that was chosen by the search, i.e. estimator
which gave highest score (or smallest loss if specified)
on the left out data. Not available if <code class="docutils literal notranslate"><span class="pre">refit=False</span></code>.</p>
</dd>
<dt><strong>best_score_</strong><span class="classifier">float</span></dt><dd><p>Mean cross-validated score of the best_estimator.</p>
</dd>
<dt><strong>best_params_</strong><span class="classifier">dict</span></dt><dd><p>Parameter setting that gave the best results on the hold out data.</p>
</dd>
<dt><strong>best_index_</strong><span class="classifier">int</span></dt><dd><p>The index (of the <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> arrays) which corresponds to the best
candidate parameter setting.</p>
<p>The dict at <code class="docutils literal notranslate"><span class="pre">search.cv_results_['params'][search.best_index_]</span></code> gives
the parameter setting for the best model, that gives the highest
mean score (<code class="docutils literal notranslate"><span class="pre">search.best_score_</span></code>).</p>
</dd>
<dt><strong>scorer_</strong><span class="classifier">function or a dict</span></dt><dd><p>Scorer function used on the held out data to choose the best
parameters for the model.</p>
</dd>
<dt><strong>n_splits_</strong><span class="classifier">int</span></dt><dd><p>The number of cross-validation splits (folds/iterations).</p>
</dd>
<dt><strong>refit_time_</strong><span class="classifier">float</span></dt><dd><p>Seconds used for refitting the best model on the whole dataset.</p>
<p>This is present only if <code class="docutils literal notranslate"><span class="pre">refit</span></code> is not False.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<div style='clear:both'></div></div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="dabl.plot.class_hists.html" class="btn btn-neutral float-right" title="dabl.plot.class_hists" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="dabl.search.GridSuccessiveHalving.html" class="btn btn-neutral float-left" title="dabl.search.GridSuccessiveHalving" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Andreas Mueller

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>
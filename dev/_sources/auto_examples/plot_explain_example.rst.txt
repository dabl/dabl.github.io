
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_explain_example.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_explain_example.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_explain_example.py:


Model Explanation
=================

.. GENERATED FROM PYTHON SOURCE LINES 5-19



.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_explain_example_001.png
         :alt: ROC curve for class 0, ROC curve for class 1, ROC curve for class 2
         :srcset: /auto_examples/images/sphx_glr_plot_explain_example_001.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_explain_example_002.png
         :alt: class: 0, class: 1, class: 2
         :srcset: /auto_examples/images/sphx_glr_plot_explain_example_002.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Running DummyClassifier()
    accuracy: 0.399 recall_macro: 0.333 precision_macro: 0.133 f1_macro: 0.190
    === new best DummyClassifier() (using recall_macro):
    accuracy: 0.399 recall_macro: 0.333 precision_macro: 0.133 f1_macro: 0.190

    Running GaussianNB()
    accuracy: 0.970 recall_macro: 0.971 precision_macro: 0.977 f1_macro: 0.971
    === new best GaussianNB() (using recall_macro):
    accuracy: 0.970 recall_macro: 0.971 precision_macro: 0.977 f1_macro: 0.971

    Running MultinomialNB()
    accuracy: 0.970 recall_macro: 0.969 precision_macro: 0.977 f1_macro: 0.971
    Running DecisionTreeClassifier(class_weight='balanced', max_depth=1)
    accuracy: 0.526 recall_macro: 0.585 precision_macro: 0.430 f1_macro: 0.460
    Running DecisionTreeClassifier(class_weight='balanced', max_depth=5)
    accuracy: 0.827 recall_macro: 0.831 precision_macro: 0.842 f1_macro: 0.826
    Running DecisionTreeClassifier(class_weight='balanced', min_impurity_decrease=0.01)
    accuracy: 0.842 recall_macro: 0.844 precision_macro: 0.849 f1_macro: 0.838
    Running LogisticRegression(C=0.1, class_weight='balanced', max_iter=1000)
    accuracy: 0.977 recall_macro: 0.979 precision_macro: 0.978 f1_macro: 0.978
    === new best LogisticRegression(C=0.1, class_weight='balanced', max_iter=1000) (using recall_macro):
    accuracy: 0.977 recall_macro: 0.979 precision_macro: 0.978 f1_macro: 0.978

    Running LogisticRegression(C=1, class_weight='balanced', max_iter=1000)
    accuracy: 0.970 recall_macro: 0.973 precision_macro: 0.969 f1_macro: 0.970

    Best model:
    LogisticRegression(C=0.1, class_weight='balanced', max_iter=1000)
    Best Scores:
    accuracy: 0.977 recall_macro: 0.979 precision_macro: 0.978 f1_macro: 0.978
                  precision    recall  f1-score   support

               0       0.94      1.00      0.97        17
               1       1.00      0.94      0.97        18
               2       1.00      1.00      1.00        10

        accuracy                           0.98        45
       macro avg       0.98      0.98      0.98        45
    weighted avg       0.98      0.98      0.98        45

    [[17  0  0]
     [ 1 17  0]
     [ 0  0 10]]
    /home/circleci/miniconda/envs/testenv/lib/python3.10/site-packages/sklearn/utils/metaestimators.py:201: FutureWarning: if_delegate_has_method was deprecated in version 1.1 and will be removed in version 1.3. Use available_if instead.
      warnings.warn(






|

.. code-block:: default

    from dabl.models import SimpleClassifier
    from dabl.explain import explain
    from sklearn.datasets import load_wine
    from sklearn.model_selection import train_test_split

    wine = load_wine()

    X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target)

    sc = SimpleClassifier()

    sc.fit(X_train, y_train)

    explain(sc, X_test, y_test)


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.699 seconds)


.. _sphx_glr_download_auto_examples_plot_explain_example.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_explain_example.py <plot_explain_example.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_explain_example.ipynb <plot_explain_example.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_


.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_explain_example.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_explain_example.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_explain_example.py:


Model Explanation
=================

.. GENERATED FROM PYTHON SOURCE LINES 5-19



.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_explain_example_001.png
         :alt: ROC curve for class 0, ROC curve for class 1, ROC curve for class 2
         :srcset: /auto_examples/images/sphx_glr_plot_explain_example_001.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_explain_example_002.png
         :alt: class: 0, class: 1, class: 2
         :srcset: /auto_examples/images/sphx_glr_plot_explain_example_002.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Running DummyClassifier()
    accuracy: 0.406 recall_macro: 0.333 precision_macro: 0.135 f1_macro: 0.192
    === new best DummyClassifier() (using recall_macro):
    accuracy: 0.406 recall_macro: 0.333 precision_macro: 0.135 f1_macro: 0.192

    Running GaussianNB()
    accuracy: 0.962 recall_macro: 0.967 precision_macro: 0.965 f1_macro: 0.964
    === new best GaussianNB() (using recall_macro):
    accuracy: 0.962 recall_macro: 0.967 precision_macro: 0.965 f1_macro: 0.964

    Running MultinomialNB()
    accuracy: 0.947 recall_macro: 0.945 precision_macro: 0.959 f1_macro: 0.947
    Running DecisionTreeClassifier(class_weight='balanced', max_depth=1)
    accuracy: 0.579 recall_macro: 0.595 precision_macro: 0.447 f1_macro: 0.484
    Running DecisionTreeClassifier(class_weight='balanced', max_depth=5)
    accuracy: 0.917 recall_macro: 0.920 precision_macro: 0.926 f1_macro: 0.919
    Running DecisionTreeClassifier(class_weight='balanced', min_impurity_decrease=0.01)
    accuracy: 0.924 recall_macro: 0.929 precision_macro: 0.930 f1_macro: 0.925
    Running LogisticRegression(C=0.1, class_weight='balanced', max_iter=1000)
    accuracy: 0.977 recall_macro: 0.982 precision_macro: 0.978 f1_macro: 0.978
    === new best LogisticRegression(C=0.1, class_weight='balanced', max_iter=1000) (using recall_macro):
    accuracy: 0.977 recall_macro: 0.982 precision_macro: 0.978 f1_macro: 0.978

    Running LogisticRegression(class_weight='balanced', max_iter=1000)
    accuracy: 0.962 recall_macro: 0.966 precision_macro: 0.963 f1_macro: 0.963

    Best model:
    LogisticRegression(C=0.1, class_weight='balanced', max_iter=1000)
    Best Scores:
    accuracy: 0.977 recall_macro: 0.982 precision_macro: 0.978 f1_macro: 0.978
                  precision    recall  f1-score   support

               0       1.00      1.00      1.00        18
               1       1.00      1.00      1.00        17
               2       1.00      1.00      1.00        10

        accuracy                           1.00        45
       macro avg       1.00      1.00      1.00        45
    weighted avg       1.00      1.00      1.00        45

    [[18  0  0]
     [ 0 17  0]
     [ 0  0 10]]
    /home/circleci/miniconda/envs/testenv/lib/python3.10/site-packages/sklearn/utils/metaestimators.py:201: FutureWarning: if_delegate_has_method was deprecated in version 1.1 and will be removed in version 1.3. Use if_available instead.
      warnings.warn(






|

.. code-block:: default

    from dabl.models import SimpleClassifier
    from dabl.explain import explain
    from sklearn.datasets import load_wine
    from sklearn.model_selection import train_test_split

    wine = load_wine()

    X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target)

    sc = SimpleClassifier()

    sc.fit(X_train, y_train)

    explain(sc, X_test, y_test)


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.685 seconds)


.. _sphx_glr_download_auto_examples_plot_explain_example.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_explain_example.py <plot_explain_example.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_explain_example.ipynb <plot_explain_example.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

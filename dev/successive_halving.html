

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Searching optimal parameters with successive halving &mdash; dabl  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'./',
              VERSION:'',
              LANGUAGE:'None',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/js/copybutton.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/project-template.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> dabl
          

          
          </a>

          
            
            
              <div class="version">
                0.0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">Quickstart to ML with dabl</a></li>
</ul>
<p class="caption"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html">Machine Learning with dabl</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">dabl API</a></li>
</ul>
<p class="caption"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="auto_examples/index.html">General examples</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">dabl</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Searching optimal parameters with successive halving</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/successive_halving.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="searching-optimal-parameters-with-successive-halving">
<span id="successive-halving-user-guide"></span><h1>Searching optimal parameters with successive halving<a class="headerlink" href="#searching-optimal-parameters-with-successive-halving" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal"><span class="pre">dabl</span></code> provides the <a class="reference internal" href="generated/dabl.search.GridSuccessiveHalving.html#dabl.search.GridSuccessiveHalving" title="dabl.search.GridSuccessiveHalving"><code class="xref py py-class docutils literal"><span class="pre">dabl.search.GridSuccessiveHalving</span></code></a> and
<a class="reference internal" href="generated/dabl.search.RandomSuccessiveHalving.html#dabl.search.RandomSuccessiveHalving" title="dabl.search.RandomSuccessiveHalving"><code class="xref py py-class docutils literal"><span class="pre">dabl.search.RandomSuccessiveHalving</span></code></a> estimators that can be used to
search a parameter space using successive halving <a class="footnote-reference" href="#id3" id="id1">[1]</a> <a class="footnote-reference" href="#id4" id="id2">[2]</a>. Successive
halving is an iterative selection process where all candidates are evaluated
with a small amount of resources at the first iteration. Only a subset of
these candidates are selected for the next iteration, which will be
allocated more resources. What defines a resource is typically the number of
samples to train on, or the number of trees for a gradient boosting /
decision forest estimator.</p>
<p>As illustrated in the figure below, only a small subset of candidates ‘survive’
until the last iteration. These are the candidates that have consistently been
part of the best candidates across all iterations.</p>
<p>#FIXME: Put figure from <cite>plot_successive_halving_iterations.py</cite> here</p>
<p>The amount of resources <code class="docutils literal"><span class="pre">r_i</span></code> allocated for each candidate at iteration
<code class="docutils literal"><span class="pre">i</span></code> is controlled by the parameters <code class="docutils literal"><span class="pre">ratio</span></code> and <code class="docutils literal"><span class="pre">r_min</span></code> as follows:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">r_i</span> <span class="o">=</span> <span class="n">ratio</span><span class="o">**</span><span class="n">i</span> <span class="o">*</span> <span class="n">r_min</span>
</pre></div>
</div>
<p><code class="docutils literal"><span class="pre">r_min</span></code> is the amount of resources used at the first iteration and
<code class="docutils literal"><span class="pre">ratio</span></code> defines the proportions of candidates that will be selected for
the next iteration:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">n_candidates_to_keep</span> <span class="o">=</span> <span class="n">n_candidates_at_i</span> <span class="o">//</span> <span class="n">ratio</span>
</pre></div>
</div>
<p>Note that each <code class="docutils literal"><span class="pre">r_i</span></code> is a multiple of both <code class="docutils literal"><span class="pre">ratio</span></code> and <code class="docutils literal"><span class="pre">r_min</span></code>.</p>
<div class="section" id="choosing-the-budget">
<h2>Choosing the budget<a class="headerlink" href="#choosing-the-budget" title="Permalink to this headline">¶</a></h2>
<p>By default, the budget is defined as the number of samples. That is, each
iteration will use an increasing amount of samples to train on. You can however
manually specify a parameter to use as the budget with the <code class="docutils literal"><span class="pre">budget_on</span></code>
parameter. Here is an example where the budget is defined as the number of
iterations of a random forest:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">make_classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <span class="n">RandomForestClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">dabl.search</span> <span class="k">import</span> <span class="n">GridSuccessiveHalving</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
<span class="gp">... </span>              <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">base_estimator</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span> <span class="o">=</span> <span class="n">GridSuccessiveHalving</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">ratio</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">budget_on</span><span class="o">=</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">max_budget</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="go">RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,</span>
<span class="go">                       max_depth=5, max_features=&#39;auto&#39;, max_leaf_nodes=None,</span>
<span class="go">                       min_impurity_decrease=0.0, min_impurity_split=None,</span>
<span class="go">                       min_samples_leaf=1, min_samples_split=2,</span>
<span class="go">                       min_weight_fraction_leaf=0.0, n_estimators=8,</span>
<span class="go">                       n_jobs=None, oob_score=False, random_state=0, verbose=0,</span>
<span class="go">                       warm_start=False)</span>
</pre></div>
</div>
<p>Note that it is not possible to budget on a parameter that is part of the
parameter space.</p>
</div>
<div class="section" id="exhausting-the-budget">
<h2>Exhausting the budget<a class="headerlink" href="#exhausting-the-budget" title="Permalink to this headline">¶</a></h2>
<p>As mentioned above, the first iteration uses <code class="docutils literal"><span class="pre">r_min</span></code> resources. If you have
a big budget, this may be a waste of resource:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">make_classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="k">import</span> <span class="n">SVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">dabl.search</span> <span class="k">import</span> <span class="n">GridSuccessiveHalving</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">),</span>
<span class="gp">... </span>              <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">base_estimator</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="s1">&#39;scale&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span> <span class="o">=</span> <span class="n">GridSuccessiveHalving</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">ratio</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">sh</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;iter&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">r_i</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="go">iter</span>
<span class="go">0    [20]</span>
<span class="go">1    [40]</span>
<span class="go">2    [80]</span>
<span class="go">Name: r_i, dtype: object</span>
</pre></div>
</div>
<p>The search process will only use 80 resources at most, while our maximum budget
is <code class="docutils literal"><span class="pre">n_samples=1000</span></code>. Note in this case that <code class="docutils literal"><span class="pre">r_min</span> <span class="pre">=</span> <span class="pre">r_0</span> <span class="pre">=</span> <span class="pre">20</span></code>. In order
for the last iteration to use as many resources as possible, you can use the
<code class="docutils literal"><span class="pre">force_exhaust_budget</span></code> parameter:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span> <span class="o">=</span> <span class="n">GridSuccessiveHalving</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">ratio</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">force_exhaust_budget</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">sh</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;iter&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">r_i</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="go">iter</span>
<span class="go">0     [250]</span>
<span class="go">1     [500]</span>
<span class="go">2    [1000]</span>
<span class="go">Name: r_i, dtype: object</span>
</pre></div>
</div>
<p>Since <code class="docutils literal"><span class="pre">force_exhaust_budget</span></code> chooses an appropriate <code class="docutils literal"><span class="pre">r_min</span></code> to start
with, <code class="docutils literal"><span class="pre">r_min</span></code> must be set to ‘auto’.</p>
</div>
<div class="section" id="aggressive-elimination-of-candidates">
<h2>Aggressive elimination of candidates<a class="headerlink" href="#aggressive-elimination-of-candidates" title="Permalink to this headline">¶</a></h2>
<p>Ideally, we want the last iteration to evaluate <code class="docutils literal"><span class="pre">ratio</span></code> candidates. We then
just have to pick the best one. When the number budget is small with respect to
the number of candidates, the last iteration may have to evaluate more than
<code class="docutils literal"><span class="pre">ratio</span></code> candidates.:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">make_classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="k">import</span> <span class="n">SVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">dabl.search</span> <span class="k">import</span> <span class="n">GridSuccessiveHalving</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">),</span>
<span class="gp">... </span>              <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">base_estimator</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="s1">&#39;scale&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span> <span class="o">=</span> <span class="n">GridSuccessiveHalving</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">ratio</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">max_budget</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">aggressive_elimination</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">sh</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;iter&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">r_i</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="go">iter</span>
<span class="go">0    [20]</span>
<span class="go">1    [40]</span>
<span class="go">Name: r_i, dtype: object</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;iter&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">r_i</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>  <span class="c1"># number of candidates used at each iteration</span>
<span class="go">iter</span>
<span class="go">0    6</span>
<span class="go">1    3</span>
<span class="go">Name: r_i, dtype: int64</span>
</pre></div>
</div>
<p>Since we cannot use more than <code class="docutils literal"><span class="pre">max_budget=40</span></code> resources, the process has to
stop at the second iteration which evaluates more than <code class="docutils literal"><span class="pre">ratio=2</span></code> candidates.</p>
<p>Using the <code class="docutils literal"><span class="pre">aggressive_elimination</span></code> parameter, you can force the search
process to end up with less than <code class="docutils literal"><span class="pre">ratio</span></code> candidates at the last
iteration. To do this, the process will eliminate as many candidates as
necessary using <code class="docutils literal"><span class="pre">r_min</span></code> resources:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span> <span class="o">=</span> <span class="n">GridSuccessiveHalving</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">ratio</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">max_budget</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">aggressive_elimination</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">sh</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;iter&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">r_i</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="go">iter</span>
<span class="go">0    [20]</span>
<span class="go">1    [20]</span>
<span class="go">2    [40]</span>
<span class="go">Name: r_i, dtype: object</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;iter&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">r_i</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>  <span class="c1"># number of candidates used at each iteration</span>
<span class="go">iter</span>
<span class="go">0    6</span>
<span class="go">1    3</span>
<span class="go">2    2</span>
<span class="go">Name: r_i, dtype: int64</span>
</pre></div>
</div>
<p>Notice that we end with 2 candidates at the last iteration since we have
eliminated enough candidates during the first iterations, using <code class="docutils literal"><span class="pre">r_i</span> <span class="pre">=</span> <span class="pre">r_min</span> <span class="pre">=</span>
<span class="pre">20</span></code>.</p>
<div class="topic">
<p class="topic-title first">References:</p>
<table class="docutils footnote" frame="void" id="id3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>K. Jamieson, A. Talwalkar,
<a class="reference external" href="http://proceedings.mlr.press/v51/jamieson16.html">Non-stochastic Best Arm Identification and Hyperparameter
Optimization</a>, in
proc. of Machine Learning Research, 2016.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[2]</a></td><td>L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, .A Talwalkar,
<a class="reference external" href="https://arxiv.org/abs/1603.06560">Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization</a>, in Machine Learning Research
18, 2018.</td></tr>
</tbody>
</table>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Andreas Mueller

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>